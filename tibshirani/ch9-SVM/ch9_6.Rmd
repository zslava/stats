---
title: "ch9 ex 6"
output:
  html_document:
    df_print: paged
---

####a)
```{r}
set.seed(3154)
##class 1
x.one <- runif(500, 0, 90)
y.one <-  runif(500, x.one + 10, 100)

x.one.noise <- runif(50,20,80)
y.one.noise <- 5/4 * (x.one.noise - 10) + 0.1

#class 0
x.zero <- runif(500, 0, 90)
y.zero <-  runif(500, 0, x.zero - 10)

x.zero.noise <- runif(50,20,80)
y.zero.noise <- 5/4 * (x.zero.noise - 10) - 0.1

#combine all 
class.one <- 1:550
class.zero <- (1:1100)[-class.one]

x <- c(x.one, x.one.noise, x.zero, x.zero.noise)
y <- c(y.one, y.one.noise, y.zero, y.zero.noise)
plot(x[class.one], y[class.one], col="blue", pch="+", ylim = c(0,100) )
points(x[class.zero], y[class.zero], col="red", pch=4 )

```

classes are separated on `x=y` with some points exacly on this line

####b)
```{r}
require(e1071)
set.seed(555)
z = rep(0, 1100)
z[class.one] = 1
data = data.frame(x = x, y = y, z = z)
tune.out = tune(svm, as.factor(z) ~ ., data = data, kernel = "linear", ranges = list(cost = c(0.01, 
    0.1, 1, 5, 10, 100, 1000, 10000)))
print( summary(tune.out) )


print( data.frame(cost = tune.out$performances$cost, misclass = tune.out$performances$error * 
    1100) )
```

For `cost=1000`  no misclassfied  points in training data set


####c)
We now generate a random test-set of same size. This test-set satisfies the true decision boundary x=y
```{r}
set.seed(1111)
x.test = runif(1000, 0, 100)
class.one = sample(1000, 500)
y.test = rep(NA, 1000)
# Set y > x for class.one
for (i in class.one) {  #index of class.one
    y.test[i] = runif(1, x.test[i], 100)
}
# set y < x for class.zero
for (i in setdiff(1:1000, class.one)) {   #index of class zero
    y.test[i] = runif(1, 0, x.test[i])
}
plot(x.test[class.one], y.test[class.one], col = "blue", pch = "+")
points(x.test[-class.one], y.test[-class.one], col = "red", pch = 4)
```


We now make same predictions using all linear svms with all costs used in previous part.

```{r}
set.seed(30012)
z.test = rep(0, 1000)
z.test[class.one] = 1
all.costs = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)
test.errors = rep(NA, 8)
data.test = data.frame(x = x.test, y = y.test, z = z.test)
for (i in 1:length(all.costs)) {
    svm.fit = svm(as.factor(z) ~ ., data = data, kernel = "linear", cost = all.costs[i])
    svm.predict = predict(svm.fit, data.test)
    test.errors[i] = sum(svm.predict != data.test$z)
}

data.frame(cost = all.costs, `test misclass` = test.errors)
```

`cost=10` looks like the best value on test data. This is much smaller than optimal value of 10000 for training data.

####d)
We again see an overfitting phenomenon for linear kernel. A large cost tries to fit correctly classify noisy-points and hence overfits the train data. A small cost, however, makes a few errors on the noisy test points and performs better on test data.


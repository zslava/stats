---
title: "ch7-Lecture"
author: "S Zimine"
date: "12/5/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Non-Liner Models
=================================

```{r}
require(ISLR)
attach(Wage)
```

Polynomials
------------

```{r}
fit <- lm(wage~poly(age,4),data=Wage) #poly degree 4 on 1 predictor 
print(summary(fit))
```

Based on the summary of fit the Cubic polynomial (degree 3) would be sufficient.

The `poly()` function generates a basis of *orthognoal polynomials*.
Lets make a plot of the fitted function, along with the standard errors of the fit.

```{r fig.width=7, fig.height=6}
agelims <- range(age)
age.grid <- seq(from=agelims[1], to=agelims[2])
preds <- predict(fit,newdata=list(age=age.grid), se=TRUE  )
se.bands <- cbind(preds$fit+2*preds$se  , preds$fit-2*preds$se )
plot(age,wage,col="darkgrey")
lines(age.grid, preds$fit, lwd=2, col="blue")
matlines(age.grid, se.bands,col="blue", lty=2)
```

There are other more direct ways of doing this plot in R. for example

```{r}
## with I()
fita <- lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
print(summary(fita))

```

Coefficients are not the same but the fitted polynomials ARE. 
```{r}
plot(fitted(fit), fitted(fita))
```

How to test a nested sequence of models on the importance of their terms? Use `anova()`

```{r}
fita <- lm(wage~education,data=Wage)
fitb <- lm(wage~education+age,data=Wage)
fitc <- lm(wage~education+poly(age,2), data=Wage)
fitd <- lm(wage~education+poly(age,3), data=Wage)

anova(fita,fitb,fitc,fitd)
```

We observe that polynomial of age up to degree 2 is significant but not of degree 3.



### Polynomial logistic 

Now we fit a logistic regression model to a binary response variable, constructed from `Wage`.
We can observe from a plot a band of high earners (`>250K`)

```{r}
lgfit <- glm(I(wage>250) ~ poly(age,3), data=Wage, family=binomial)
print(summary(fit))

preds <- predict(lgfit, list(age=age.grid), se=TRUE)
se.bands <- preds$fit + cbind(fit=0, lower=-2*preds$se, upper=2*preds$se)

print(se.bands[1:5,] )
```

We have done a computations on the logit scale, To transfer to probabilistic scale we need 
to apply the inverse logit mapping 

$$ p=\frac{e^\eta}{1+e^\eta} $$

```{r}
prob.bands <- exp(se.bands) / (1+exp(se.bands))
matplot(age.grid, prob.bands,col="blue", lwd=c(2,1,1), lty=c(1,2,2),
        type="l", ylim=c(0,.1)  )
points(jitter(age), I(wage>250)/10, pch="l", cex=.5)

```

We observe that only 4% of population earn  more than 250 K. 


Splines
===========

Splines are more flexible than polynomials, but the idea is rather similar. 
Here we will explore cubic splines 

```{r}
require(splines)
fit<-lm(wage~bs(age,knots=c(25,40,60)), data=Wage )
plot(age,wage, col="darkgrey")
lines(age.grid, predict(fit, list(age=age.grid)),col="darkgreen",lwd=2 )
abline(v=c(25,50,60), lty=2, col="darkgreen" )
summary(fit)
fit <- smooth.spline(age,wage, df=16) # knots an be undefined for smooth.spline
lines(fit,col="red", lwd=2)
fit<- smooth.spline(age,wage, cv=TRUE)  # using cross-validation to find df param
lines(fit, col="purple", lwd=2)

```

The smoothing splines does not require knot selection, but it does have a smoothing parametere, which can conveniently be specified via the effective degrees of freedom or `df`.


Generalized Additive Models
----------------------------

So far we have focused on fitting models with mostly single nonlinear terms. 
The `gam` package makes it easier to work wit multiple nonlinear terms.  In addition it knows how to plot these functions and their standard errors. 

```{r fig.width=10, fig.height=5}
require(gam)
gam1<- gam(wage~s(age,df=4)+s(year, df=4)+education, data=Wage)
# s() is a smoothing spline for specified variable in a package gam
par( mfrow=c(1,3))
plot(gam1,se=TRUE)
```

For logistics regression

```{r fig.width=10, fig.height=5}
gam2 <- gam(I(wage>250)~s(age,df=4)+s(year, df=4)+education
            , data=Wage, family=binomial )
par( mfrow=c(1,3))
plot(gam2)
```

Lets check if we really need a spline for a `year` predictor

```{r}
gam2a <- gam(I(wage>250)~s(age,df=4)+year+education, data=Wage, family=binomial )
anova(gam2a,gam2,test="Chisq")
```

The p-value = 0.82 is high so a polynomial for `year` is not necessary.


One nice feature of the `gam` pkg  is that it knows how to plot the functions nicely even for models fit by `lm` or `glm`.

```{r fig.width=10, fig.height=5}
par(mfrow=c(1,3))
lm1 <- lm(wage~ns(age,df=4)+ns(year,df=4)+education
          ,data=Wage )
plot.gam(lm1,se=TRUE)
```





